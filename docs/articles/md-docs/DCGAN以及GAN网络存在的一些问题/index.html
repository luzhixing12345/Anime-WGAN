<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        Document
    </title>
    <link rel='stylesheet' href=../../../css/prism.css /><link rel='stylesheet' href=../../../css/index.css />
    <link rel="icon" href="https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png">
</head>

<body class="light">
    <a href="https://github.com/luzhixing12345/Anime-WGAN.git" target="_blank" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <div class="header-navigator"><ul><li><a href="#h1-0">DCGAN以及GAN网络存在的一些问题</a><ul><li><a href="#h2-1">DCGAN</a><ul><li><a href="#h3-2">潜在空间的探索</a></li></ul></li></ul><ul><li><a href="#h2-3">GAN网络存在的问题</a></li></ul><ul><li><a href="#h2-4">mode dropping / mode collapse</a></li></ul></li></ul></div><div class='markdown-body'><h1 id="h1-0">DCGAN以及GAN网络存在的一些问题</h1><h2 id="h2-1"><a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank">DCGAN</a></h2><p>这篇论文主要针对于GAN网络的经典问题: GANs have been known to be unstable to train, often resulting in generators that produce nonsensical outputs. 进而提出了使用深度卷积神经网络来改进</p><p>作者在论文中提出了了一些改进措施,比如</p><ul><li>在生成器G中将去掉池化层(如maxpooling),替换为快速卷积,允许网络学习它自己的空间下采样(downsampling)</li></ul><ul><li>去除全连接层,作者认为全局平均池增加了模型的稳定性,但损害了收敛速度</li></ul><ul><li>以及加入BatchNormalization</li></ul><ul><li>特定位置使用ReLU,Tanh,LeakyReLU等激活函数</li></ul><p>并且作者也指出了一些训练过程中的超参数,权重值,优化器学习率等等,一些细节不再这里赘述了,有兴趣的可以去看一下论文</p><p>DCGAN的生成器G网络结构如下图所示:</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518010527.png" alt="20220518010527"></p><p>输入是一个<code>100x1x1</code>维的向量,首先将其转置卷积为<code>1024x4x4</code>,然后逐步转置卷积,最后得到一个<code>3x64x64</code>的图片</p><p>然后作者也做了跨数据集的分类问题的研究,在Imagenet-1k数据集中训练判别器D然后接一个L2-SVM的分类器,取得了82.8%的准确率.</p><p>从结构上来看,DCGAN比常见的判别式网络更加线性,因为连max pooling都没了,不那么线性的部分就只有最后输出图片的Tanh.</p><h3 id="h3-2">潜在空间的探索</h3><p>作者提到了一个名词 <code>walking the latent space</code>,中译为<b>探索潜在空间</b></p><blockquote><p>参考文章<a href="https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d" target="_blank">了解机器学习中的潜在空间</a></p></blockquote><ul><li>什么是潜在空间呢?</li></ul><p>它意味着压缩过的数据.对于经典的手写数据集MNIST,如果我们训练一个神经网络来实现它的分类问题</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518013126.png" alt="20220518013126"></p><p>每次模型通过数据点学习时,图像的维度首先会降低,然后才会最终增加.当维度降低时,我们认为这是一种有损压缩形式.</p><p>由于模型需要然后重建压缩数据,因此它必须学会存储所有相关信息并忽略噪声这就是压缩的价值.<b>它使我们能够摆脱任何无关的信息,只关注最重要的功能</b></p><p>这种压缩状态被称为数据的潜在空间.</p><ul><li>那么为什么被称为空间呢?</li></ul><p>每当我们绘制点图或想到潜在空间中的点时,我们都可以将它们想象为空间中的坐标,其中相似的点在图上更接近.</p><p>一个自然而然的问题是,我们如何想象4D点或n维点甚至非向量的空间,我们是3维生物,无法理解n维空间,我们只能假想一个超空间来映射多维空间的点,而相似的点在这个空间更加"接近"?或者说"相似"?</p><ul><li>那么什么是相似呢?</li></ul><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518013758.png" alt="20220518013758"></p><p>如果我们看三个图像,两个椅子和一个桌子,我们很容易说两个椅子图像最相似,而桌子与任何一个椅子图像最不同.但是什么让这两把椅子的形象"更相似"呢?椅子具有明显的特征(即靠背,无抽屉,腿之间的连接).这些都可以被我们的模型通过学习边缘,角度等的模式来"理解".</p><p>如前所述,这些特征被打包在数据的潜在空间表示中.</p><p>因此,随着维数的降低,每个图像不同的"无关"信息(即椅子颜色)从我们的潜在空间表示中"删除",因为只有每个图像最重要的特征存储在潜在空间表示中.</p><p>因此,当我们降低维度时,两把椅子的表示变得不那么明显,更加相似.如果我们想象它们在太空中,它们会"更紧密"地结合在一起.</p><p>*请注意,这里提到的"接近度"度量是一个模棱两可的术语,而不是明确的欧几里得距离,因为空间中的距离有多种定义.</p><ul><li>那么探索潜在空间有什么意义呢?</li></ul><p>潜在空间"隐藏"在我们最喜欢的许多图像处理网络、生成模型等中.</p><p>虽然潜空间对大多数人来说是隐藏的,但在某些任务中,理解潜空间不仅有帮助,而且是必要的.</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518014319.png" alt="20220518014319"></p><p>在3D中,我们知道存在类似数据点的组,但是用更高维的数据描绘这些组要困难得多.</p><p>通过将数据的维数降低到2D(在这种情况下可以被认为是"潜在空间"表示),我们能够更轻松地区分数据集中的流形(相似数据组)</p><p>我们可以使用<b>在潜在空间中插值</b>的方式来探索不同的面部结构,这也是用来研究GAN网络过程中相当有趣的一个工作</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518014511.png" alt="20220518014511"></p><ul><li>什么是在潜在空间中插值?</li></ul><p>其实很简单,对于两个值X(a1,b1,...z1)和Y(a2,b2,...z2),我们可以使用GAN网络各自生成他们对应的图片,这没有问题.</p><p>而线性插值就是依次探索这两个高维点之间的空间,可以用来研究它们之间的过渡/变化过程</p><pre><code class="language-python">import torch
X = torch.randn((5,5,5,5))
Y = torch.randn((5,5,5,5))

alpha = 0
walk_step = 100
images = []
G = generator()

for i in range(walk_step):
    point = alpha * X + (1-alpha) * Y
    images.append(G(point))
    alpha = alpha + 1/walk_step
# then do visiualization for images to see latent space for generator</code></pre><p>上图就体现出了这个转变的过程</p><p>关于latent space 的相关内容这里再扩展一些,因为目前做的都是线性插值,即直接取了两点之间的直线,有人认为在高维空间中数据其实分布在帐篷布上,但是线性插值的方法其实走的是帐篷杆,应该用一种更好的方式Slerp.详见<a href="https://zhuanlan.zhihu.com/p/32135185" target="_blank">知乎-行走在GAN的Latent Space</a>,作者也讨论了Great Circle也做了一些实验,我觉得还是很值得一看的.</p><p>总结来说DCGAN依靠的是对判别器和生成器的架构进行实验枚举,最终找到一组比较好的网络架构设置,但是实际上是治标不治本,没有彻底解决问题.GAN网络的训练依旧十分困难</p><h2 id="h2-3"><a href="https://arxiv.org/abs/1701.04862" target="_blank">GAN网络存在的问题</a></h2><blockquote><p>参考文章:</p><p><a href="https://zhuanlan.zhihu.com/p/58260684" target="_blank">WGAN的来龙去脉</a></p><p><a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank">令人拍案叫绝的WGAN</a></p><p><a href="https://jonathan-hui.medium.com/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b" target="_blank">为什么GAN网络难以训练</a></p></blockquote><p>在介绍WGAN之前,我们需要先了解GAN网络存在的问题,WGAN的一作作者Martin Arjovsky在2017年先后参与了三篇相关论文,第一篇论文"Towards Principled Methods for Training Generative Adversarial Networks",这篇论文是WGAN发表前的铺垫,它最大的贡献是从理论上解释了GAN训练不稳定的原因.</p><p>人们在应用GAN时经常发现一个现象:不能把Discriminator训练得太好,否则Generator的性能很难提升上去.该文以此为出发点分析了GAN目标函数的理论缺陷.</p><p>在上一节中,我们提到了GAN网络的目标函数</p><p>$$\min\limits_{G}\max\limits_{D}V(D,G) = E_{x\thicksim p_{data(x)}}[\log D(x)] + E_{z\thicksim p_{z(z)}}[\log(1-D(G(z)))]$$</p><p>同时证明了,固定Generator时,最优的Discriminator的取值是</p><p>$$D^*_G(x) = \frac{P_{data}(x)}{P_{data}(x) + P_g(x)}$$</p><p>所以在面对最优Discriminator时,Generator的优化目标就变成了</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518000942.png" alt="20220518000942"></p><p>写成JS散度的形式就是</p><p>$$C(G) = -\log4 + 2*JSD(p_{data}||p_g)$$</p><p>所以现在这个问题被转化为:<b>在最优判别器的下,我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布$P_{data}$与生成分布$P_g$之间的JS散度.我们越训练判别器,它就越接近最优,最小化生成器的loss也就会越近似于最小化$P_{data}和$P_g$之间的JS散度</b></p><p>问题就出在这个JS散度上.我们会希望如果两个分布之间越接近它们的JS散度越小,我们通过优化JS散度就能将$P_g$"拉向"真实分布$P_{data}$</p><p>这个希望在两个分布有所重叠的时候是成立的,也就是最终的优化目标$P_g = P_{data}$.但是如果两个分布完全没有重叠的部分,或者它们重叠的部分可忽略,它们的JS散度是多少呢?</p><ul><li>重叠的部分可忽略是什么意思?</li></ul><p>GAN中的生成器一般是从某个低维(比如100维)的随机分布中采样出一个编码向量,再经过一个神经网络生成出一个高维样本(比如64x64的图片就有4096维).当生成器的参数固定时,生成样本的概率分布虽然是定义在4096维的空间上,但它本身所有可能产生的变化已经被那个100维的随机分布限定了,其本质维度就是100,再考虑到神经网络带来的映射降维,最终可能比100还小,所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形,"撑不满"整个高维空间.</p><p>"撑不满"就会导致真实分布与生成分布难以"碰到面",这很容易在二维空间中理解:</p><ul><li>二维平面中随机取两条曲线,它们之间刚好存在重叠线段的概率为0</li></ul><ul><li>虽然它们很大可能会存在交叉点,但是相比于两条曲线而言,交叉点比曲线低一个维度,长度(测度)为0,可忽略</li></ul><p>三维空间中也是类似的,随机取两个曲面,它们之间最多就是比较有可能存在交叉线,但是交叉线比曲面低一个维度,面积(测度)是0,可忽略.</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/v2-45852cfbb4fcf2943e7d6eafcb9ed054_720w.jpg" alt="v2-45852cfbb4fcf2943e7d6eafcb9ed054_720w"></p><p>那么回到刚才的问题,如何计算两个分布的JS散度呢? 我们惊讶的发现这是一个定值 $\log2$</p><p>对于任意的空间中任意选定的一点x,在真实分布$P_{data}$与生成分布$P_g$中的概率有四种情况</p><ul><li>$P_{data}(x) = 0,P_g(x) = 0$, 这种情况对JS的计算无贡献,可以理解为选点选歪了</li></ul><ul><li>$P_{data}(x) \neq 0,P_g(x) \neq 0$, 这种情况下说明选点选到了重叠部分,但是由于重叠部分可忽略所以贡献也为0</li></ul><ul><li>$P_{data}(x) \neq 0,P_g(x) = 0$<p>根据之前的得到的公式</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518182315.png" alt="20220518182315"></p></li></ul><ul><li>$P_{data}(x) = 0,P_g(x) \neq 0$ 情况相同</li></ul><p>换句话说,无论真实分布$P_{data}$与生成分布$P_g$是远在天边,还是近在眼前,只要它们俩没有一点重叠或者重叠部分可忽略,JS散度就固定是常数,而这对于梯度下降方法意味着<b>梯度为0!</b>此时对于最优判别器来说,生成器肯定是得不到一丁点梯度信息的;即使对于接近最优的判别器来说,生成器也有很大机会面临梯度消失的问题</p><blockquote><p>参考<a href="https://zhuanlan.zhihu.com/p/357141352" target="_blank">难以优化的GAN</a></p></blockquote><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/v2-d134d150cc3032ec6cb47c9ceb68139c_720w.jpg" alt="https://zhuanlan.zhihu.com/p/357141352"></p><p>我们就得到了WGAN前作中关于生成器梯度消失的第一个论证:在(近似)最优判别器下,最小化生成器的loss等价于最小化$P_{data}$与$P_g$之间的JS散度,而由于$P_{data}$与$P_g$几乎不可能有不可忽略的重叠,所以无论它们相距多远JS散度都是常数$-\log2$,最终导致生成器的梯度(近似)为0,梯度消失</p><p>JS散度是f散度的一种,所有的f散度都具有一个问题,那就是在两个分布几乎没有交集的时候,散度为一个常数,这意味着梯度为零,而我们是使用梯度下降求解的,所以这意味着我们无法很好地完成优化</p><ul><li>好消息:两个分布完全无重叠,则一定存在一个最优分类器,能够使得对两种分布样本的分类精度达到100%.也就是说在GAN的判别器优化过程中,那个我们心心念念寻找的完美判别器是一定存在的,我们放开手去找就是了</li></ul><ul><li>坏消息:JS作为损失函数输出为常数,即梯度为0,意味着我们在优化生成器时,梯度下降法将不知道朝哪个方向下降.</li></ul><p>该文花了大量的篇幅进行数学推导,证明在一般的情况下,上述有关JS散度的目标函数会带来梯度消失的问题.也就是说,如果Discriminator训练得太好,Generator就无法得到足够的梯度继续优化,而如果Discriminator训练得太弱,指示作用不显著,同样不能让Generator进行有效的学习.这样一来,Discriminator的训练火候就非常难把控,这就是GAN训练难的根源.</p><h2 id="h2-4">mode dropping / mode collapse</h2><ul><li>什么是 <code>mode collapse</code></li></ul><p>指的是生成样本只集中于部分的mode从而缺乏多样性的情况.例如,MNIST数据分布一共有10个mode(0到9共10个数字),如果Generator生成的样本几乎只有其中某个数字,那么就是出现了很严重的mode collapse现象</p><p>即生成器仅仅生成部分重复的图片,缺乏多样性</p><p>mode collapse在GAN的训练中也非常的常见,比如将会在下一节中出现的示例,我自己的在使用DCGAN训练一个生成动漫头像的GAN网络,出现了十分明显的 mode collapse的现象</p><table><tr><th>epoch</th><th>生成器的部分结果</th></tr><tr><td style="text-align:center">                30</td><td style="text-align:center">                <img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220519024333.png" alt="20220519024333"></td></tr><tr><td style="text-align:center">                70</td><td style="text-align:center">                <img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220519024350.png" alt="20220519024350"></td></tr></table><p>可以很明显的看出随着训练过程的进行,生成器的图像出现了明显的重复</p><ul><li>那么为什么会造成mode collapse呢?</li></ul><p>这也是KL散度所带来的问题.我们假设有如下两个正态分布,我们可以画出需要优化的方向,即JS散度的图像</p><blockquote><p>其中p代表真实图像的分布,q代表生成的图像的分布</p></blockquote><table><tr><th><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518195329.png" alt="20220518195329"></th><th><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518211729.png" alt="20220518211729"></th></tr></table><p>当我们选取红线所在的位置(x=2),此时$p(x)\rightarrow0,q(x)&gt0$,此时对应的$D_{js}(p||q)$很大,同样的对称位置(x=-2)JS散度依然很高,也就是惩罚很高</p><ul><li>第一种情况(x=2)对应<b>生成器没能生成真实的样本</b></li></ul><ul><li>第二种情况(x=-2)对应着<b>生成器生成了不真实的样本</b>.</li></ul><p>这两种情况下的惩罚都是巨大的.导致生成器训练起来难度巨大</p><p>我们之前提到过训练生成器G的时候往往不使用 $\log(1-D(G(z)))$,因为它接近0,梯度很小,很难训练G</p><p>GAN的论文中也提出了一种改进做法是损失变为 $-\log(D(G(z)))$,这种技巧也被成为 <b>- log D trick</b>或者 <b>the - log D alternative</b>,在训练中确实有所帮助</p><p>但是这会带来另外的问题,这种情况下我们计算生成器G的梯度时</p><p>$$\Delta\theta = \nabla_{\theta}E_{z\thicksim p(z)}[-\log D(g_{\theta}(z))]$$</p><p>根据前文的数学推导可以得出这个梯度可以转化为</p><p>$$\Delta\theta = KL(P_g||P_{data})-2JS(P_{data}||P_g)$$</p><p>这个等价最小化目标存在两个严重的问题.第一是它同时要最小化生成分布与真实分布的KL散度,却又要最大化两者的JS散度,一个要拉近,一个却要推远!这在直观上非常荒谬,在数值上则会导致梯度不稳定,这是后面那个JS散度项的毛病</p><p>即便是前面那个正常的KL散度项也有毛病,我们先把这种状况下的KL散度图画出来</p><p>那么对于KL散度的定义</p><p>$KL(p||q) = \int_x p(x)\log\frac{p(x)}{q(x)}dx$</p><p>$KL(q||p) = \int_x q(x)\log\frac{q(x)}{p(x)}dx$</p><p>我们可以分别画出它们对应的图像,值得注意的是KL散度是非对称的,两个图像不相同,我们这里只需要关注$D_{kl}(Q||P)$<b>红色的曲线</b>即可</p><table><tr><th><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518195329.png" alt="20220518195329"></th><th><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220518195922.png" alt="20220518195922"></th></tr></table><ul><li>当我们选取红线所在的位置(x=2),此时$p(x)\rightarrow0,q(x)&gt0$,此时对应的$D_{kl}(Q||P)\rightarrow0$</li></ul><ul><li>当我们选取红线的对应的位置(x=-2),此时$p(x)&gt0,q(x)\rightarrow0$,此时对应的$D_{kl}(Q||P)\rightarrow1$</li></ul><p>换言之,$D_{kl}(Q||P)$对于上面两种错误的惩罚是不一样的</p><p>对于前文提到的两种情况:</p><ul><li>第一种情况(x=2)对应<b>生成器没能生成真实的样本</b></li></ul><ul><li>第二种情况(x=-2)对应着<b>生成器生成了不真实的样本</b>.</li></ul><p>第一种错误对应的是"生成器没能生成真实的样本",惩罚微小,第二种错误对应的是"生成器生成了不真实的样本" ,惩罚巨大.</p><p>我们按照"人类正常的思绪"来看,"像的生成不了"和"能生成的不像"实际表达的都是"生成器烂"这一件事儿,但是KL散度却给出了截然相反的两种惩罚结果,一个"挠痒痒"和一个"往死打"</p><p>这一放一打之下,生成器宁可多生成一些重复但是很"安全"的样本,也不愿意去生成多样性的样本,因为那样一不小心就会产生第二种错误,得不偿失.这种现象就是大家常说的<code>mode collapse</code></p><p>第一种错误对应的是缺乏多样性,第二种错误对应的是缺乏准确性</p><p>除了上述的缺陷,该文还通过数学证明这种-logD的目标函数还存在梯度方差较大的缺陷,导致训练的不稳定.然后同样通过实验直观地验证了这个现象,如下图,在训练的早期(训练了1 epoch和训练了10 epochs),梯度的方差很大,因此对应的曲线看起来比较粗,直到训练了25 epochs以后GAN收敛了才出现方差较小的梯度</p><p>可以看到随着判别器的训练,蓝色和绿色曲线中生成器的梯度迅速增长,说明梯度不稳定,红线对应的是DCGAN相对收敛的状态,梯度才比较稳定</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/v2-45ec2b5c75b83beaa5be3dea80122f2c_720w.png" alt="v2-45ec2b5c75b83beaa5be3dea80122f2c_720w"></p></div>
    <div class="dir-tree"><ul><li><a href="../../md-docs/README" >README</a></li></ul><ul><li><a href="../../md-docs/基本原理及数学推导" >基本原理及数学推导</a></li></ul><ul><li><a href="../../md-docs/DCGAN以及GAN网络存在的一些问题" >DCGAN以及GAN网络存在的一些问题</a></li></ul><ul><li><a href="../../md-docs/WGAN-CP 与 WGAN-GP" >WGAN-CP 与 WGAN-GP</a></li></ul><ul><li><a href="../../md-docs/使用WGAN生成动漫头像" >使用WGAN生成动漫头像</a></li></ul></div>
    <div class="zood"><a class="" href="https://github.com/luzhixing12345/zood" target="_blank">zood</a></div>
    <script type="text/javascript" src="../../../js/next_front.js"></script><script>addLink("../../md-docs/基本原理及数学推导","../../md-docs/WGAN-CP 与 WGAN-GP","ab")</script><script type="text/javascript" src="../../../js/change_mode.js"></script><script>addChangeModeButton("../../../img/sun.png","../../../img/moon.png")</script><script type="text/javascript" src="../../../js/copy_code.js"></script><script>addCodeCopy("../../../img/before_copy.png","../../../img/after_copy.png")</script><script type="text/javascript" src="../../../js/navigator.js"></script><script type="text/javascript" src="../../../js/prism.js"></script><script type="text/javascript" src="../../../js/picture_preview.js"></script>
        <script>
            MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']]
            }
            };
            </script>
        <script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>
        <script type="text/javascript" src="../../../js/check_box.js"></script>
</body>

</html>