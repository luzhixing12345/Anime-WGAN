<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        Document
    </title>
    <link rel='stylesheet' href=../../../css/prism.css /><link rel='stylesheet' href=../../../css/index.css />
    <link rel="icon" href="https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png">
</head>

<body class="light">
    <a href="https://github.com/luzhixing12345/Anime-WGAN.git" target="_blank" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <div class="header-navigator"><ul><li><a href="#h1-0">使用WGAN生成动漫头像</a><ul><li><a href="#h2-1">简介</a></li></ul><ul><li><a href="#h2-2">有关模型</a></li></ul></li></ul></div><div class='markdown-body'><h1 id="h1-0">使用WGAN生成动漫头像</h1><p>本文将会介绍一个我的项目,使用WGAN-GP生成动漫头像.</p><p>项目地址: <a href="https://github.com/luzhixing12345/Anime-WGAN" target="_blank">Github-Anime-WGAN</a></p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/WGAN64_anime.png" alt="最终结果"></p><h2 id="h2-1">简介</h2><p>其实这个项目的起因很简单,就是想动手实践一下,顺着GAN往下学就到了WGAN-GP,然后就搜了搜代码找了一个<a href="https://github.com/Zeleni9/pytorch-wgan" target="_blank">很不错的项目</a>跟着改了改,然后完成了这次任务</p><p>关于具体的训练细节,实验结果,潜在空间探索等等内容我都在项目的README里面写的很详细了,这里不再赘述,主要想讲一讲一些细节的部分</p><h2 id="h2-2">有关模型</h2><p>DCGAN,WGAN模型都继承了BasicGAN,所有的函数定义,基本实现什么的也都放在了这里,子类专注于重载train方法就可以了</p><p>最开始我尝试了DCGAN来训练,遇到了经典的 mode collapse问题, 详见之前的文章.于是我调查了一些原因,最后选择使用WGAN-GP来跑</p><p>最开始的我找的两个数据集都是96x96的,然后我改了改模型的结构,输出了一份64x64的动漫头像</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220519175407.png" alt="20220519175407"></p><p>这是一些比较好的结果,看起来还不错</p><p>然后我就想扩大这个图像的分辨率,变成256x256的,然后我就想找一个数据集256x256像素的,但是没找到.然后我索性就直接搞了爬虫去自己爬,然后动漫人脸识别,然后再剔除不好的样本,前前后后搞了好长好长时间,数据集在<a href="https://github.com/luzhixing12345/anime-face-dataset" target="_blank">这里</a>,结果第二天我就找到了一个512x512的数据集,更大,更好,真的不知道说啥了...</p><p>接下来就是该模型,于是我就照葫芦画瓢呗,改一个256x256的,但是马上就出了问题</p><p>首先就是来的一个问题,模型太大了,连续的卷积这个维度太高了,爆显存了.于是我又调整维度,又去改batch size,最后好不容易可以正常训练了.</p><p>然后又马上来了一个更致命的问题,生成的图像及其诡异,具有非常明显的诡异色块?这我也没改啥啊? 于是我赶紧去调查了一下,发现了这其实是一个转置卷积操作带来的问题 : 棋盘效应</p><blockquote><p>反卷积有许多解释和不同的名称,包括"转置卷积"</p></blockquote><p>关于这个问题,这篇<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank">文章</a>其实已经探讨的非常详细了</p><p>问题就是出在这个转置卷积的操作 <code>nn.ConvTranspose2d</code>.当我们让神经网络生成图像时,我们经常让它们从低分辨率、高级描述中构建图像.这允许网络描述粗略的图像,然后生成详细图像</p><p>为了做到这一点,我们需要一些方法来从较低分辨率的图像到较高的图像.我们通常使用反卷积运算来执行此操作.粗略地说,反卷积层允许模型使用小图像中的每个点在较大的图像中"绘制"正方形</p><p>不幸的是,反卷积很容易产生"<b>不均匀的重叠</b>",在某些地方比在其他地方放置更多的隐喻颜料.特别是,<b>当内核大小(输出窗口大小)不能被步幅(顶部点之间的间距)整除时,反卷积具有不均匀的重叠</b>.虽然原则上,网络可以仔细学习权重以避免这种情况,但实际上神经网络很难完全避免它</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/qwexqdq.gif" alt="qwexqdq"></p><p>一个更加直观的例子</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/huohqw.gif" alt="huohqw"></p><p>现在,神经网络在创建图像时通常使用多层反卷积,从一系列较低分辨率的描述中迭代构建更大的图像.虽然这些堆叠的反卷积可以抵消伪像,但它们通常会复合,从而在各种尺度上创建伪影</p><p>一种方法是将上采样从卷积分离到更高的分辨率,以计算特征.例如,您可以调整图像大小(使用最近邻插值或双线性插值),然后执行卷积层.这似乎是一种自然的方法,并且大致类似的方法在图像超分辨率</p><p>这就是我为什么又给64x64的模型补做了WGANP,它的改变就是将 <code>nn.ConvTranspose2d</code> 调整为 <code>nn.Unsample + nn.Conv2d</code></p><table><tr><th><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220519181337.png" alt="20220519181337"></th><th><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220519181431.png" alt="20220519181431"></th></tr></table><blockquote><p>虽然在64x64的并不明显,但是要是在256x256里使用反卷积这种棋盘效应会及其明显,很遗憾我并没有保留当时的图片,现在也找不到了,不过确实及其明显</p></blockquote><p>后来我改成了上采样+卷积仍然效果不好,依然很差很差,于是我又去找了找其他的论文,发现了一个<a href="https://arxiv.org/pdf/1708.05509.pdf" target="_blank">论文</a>也是做这个动漫头像生成的,但是这个论文比较早了,更新的论文我也没有去调研,有点懒得搞了.</p><p>这个论文还给了一个可以直接在线体验的网站: <a href="https://make.girls.moe" target="_blank">https://make.girls.moe</a>/#/ , 感觉还是挺好的,虽然有时候头发颜色白色生成的不是很好(老白毛控了)然后我就去学这篇论文的架构,它用了残差的思想,所以我也加了残差连接,结果还是不理想,现在大概是长成这样</p><p><img src="https://raw.githubusercontent.com/learner-lu/picbed/master/20220519182307.png" alt="20220519182307"></p><p>后来我就懒得搞了,搞一个64x64得了,一下子扩展维度这个怕是有点困难,也许小模型还凑活看看大模型就不太好使了</p><p>有关评价指标可以参考<a href="https://zhuanlan.zhihu.com/p/432965561" target="_blank">文章</a></p></div>
    <div class="dir-tree"><ul><li><a href="../../md-docs/README" >README</a></li></ul><ul><li><a href="../../md-docs/基本原理及数学推导" >基本原理及数学推导</a></li></ul><ul><li><a href="../../md-docs/DCGAN以及GAN网络存在的一些问题" >DCGAN以及GAN网络存在的一些问题</a></li></ul><ul><li><a href="../../md-docs/WGAN-CP 与 WGAN-GP" >WGAN-CP 与 WGAN-GP</a></li></ul><ul><li><a href="../../md-docs/使用WGAN生成动漫头像" >使用WGAN生成动漫头像</a></li></ul></div>
    <div class="zood"><a class="" href="https://github.com/luzhixing12345/zood" target="_blank">zood</a></div>
    <script type="text/javascript" src="../../../js/next_front.js"></script><script>addLink("../../md-docs/WGAN-CP 与 WGAN-GP",".","ab")</script><script type="text/javascript" src="../../../js/change_mode.js"></script><script>addChangeModeButton("../../../img/sun.png","../../../img/moon.png")</script><script type="text/javascript" src="../../../js/copy_code.js"></script><script>addCodeCopy("../../../img/before_copy.png","../../../img/after_copy.png")</script><script type="text/javascript" src="../../../js/navigator.js"></script><script type="text/javascript" src="../../../js/prism.js"></script><script type="text/javascript" src="../../../js/picture_preview.js"></script>
        <script>
            MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']]
            }
            };
            </script>
        <script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>
        <script type="text/javascript" src="../../../js/check_box.js"></script>
</body>

</html>